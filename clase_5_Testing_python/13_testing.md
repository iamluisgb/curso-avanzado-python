# ğŸ”¹Â Fundamentos del Testing en Python

# Â¿QuÃ© son las Pruebas Unitarias y por quÃ© es importante?

Probar software no solo es una tarea tÃ©cnica, es un proceso crÃ­tico que puede marcar la diferencia entre el Ã©xito o el fracaso de un proyecto. Un pequeÃ±o error no detectado puede causar grandes problemas, como lo demuestra el caso del cohete de la Agencia Espacial Europea en 1996. Afortunadamente, en el desarrollo de software contamos con herramientas como Python y sus mÃ³dulos para asegurar la calidad del cÃ³digo antes de que llegue a los usuarios.

## **Â¿QuÃ© tipos de pruebas son necesarias para asegurar la calidad del software?**

- **Pruebas unitarias:**Â Se encargan de validar que cada componente pequeÃ±o del cÃ³digo funcione correctamente de manera aislada.
- **Pruebas de integraciÃ³n:**Â Verifican que los distintos componentes trabajen bien en conjunto, evitando problemas en la interacciÃ³n de partes.
- **Pruebas funcionales:**Â Validan que el sistema en su totalidad funcione como se espera segÃºn los requisitos.
- **Pruebas de rendimiento:**Â Aseguran que el software sea rÃ¡pido y eficiente, evaluando su comportamiento bajo diferentes condiciones de carga.
- **Pruebas de aceptaciÃ³n:**Â Determinan si el software cumple con las expectativas del usuario final.


## **Â¿QuÃ© herramientas de testing ofrece Python?**

- **UnitTest:**Â Permite crear pruebas unitarias de manera sencilla, asegurando que todas las partes del cÃ³digo realicen su funciÃ³n correctamente.
- **PyTest:**Â Facilita la creaciÃ³n de pruebas con una configuraciÃ³n avanzada para cubrir diferentes escenarios.
- **DocTest:**Â Integra pruebas directamente en los comentarios de las funciones, permitiendo validar el cÃ³digo mientras se mantiene la documentaciÃ³n.

## **Â¿CÃ³mo garantizar que todas las lÃ­neas de cÃ³digo estÃ¡n siendo probadas?**

Es crucial identificar las lÃ­neas de cÃ³digo que no estÃ¡n cubiertas por pruebas. Para esto, existeÂ **Coverage**, una herramienta que genera un reporte en HTML mostrando quÃ© partes del cÃ³digo no han sido validadas, lo que permite agregar pruebas adicionales donde sea necesario.

## **Â¿Por quÃ© es importante el testing en software?**

El testing asegura que el software sea funcional, rÃ¡pido y confiable, pero mÃ¡s allÃ¡ de eso, puede evitar costosos errores, pÃ©rdidas financieras y en casos extremos, salvar vidas. Al probar el software antes de que llegue a producciÃ³n, los desarrolladores tienen la ventaja de corregir fallos antes de que impacten a los usuarios.

# Â¿QuÃ© es el Testing en Software?

Las pruebas en el desarrollo de software son esenciales para garantizar la calidad y estabilidad del cÃ³digo antes de lanzarlo a producciÃ³n. Tanto las pruebas manuales como las automatizadas juegan un rol fundamental para detectar errores. Usar Python para automatizar estas pruebas no solo ahorra tiempo, sino que tambiÃ©n asegura que los errores crÃ­ticos se detecten antes, evitando posibles pÃ©rdidas econÃ³micas y de confianza de los usuarios.

## **Â¿QuÃ© son las pruebas manuales y cÃ³mo funcionan?**

Las pruebas manuales consisten en validar el funcionamiento de un cambio en el cÃ³digo mediante la interacciÃ³n directa con la aplicaciÃ³n. Esto se hace, por ejemplo, al modificar una lÃ­nea de cÃ³digo, ejecutar la aplicaciÃ³n y verificar si el cambio funciona correctamente. Es similar al trabajo de un mecÃ¡nico que ajusta un auto y luego lo prueba encendiÃ©ndolo cada vez.

## **Â¿CÃ³mo funcionan las pruebas unitarias?**

Las pruebas unitarias permiten validar que pequeÃ±as piezas de cÃ³digo, como funciones individuales, trabajan correctamente. En el ejemplo de un mecÃ¡nico, esto serÃ­a como revisar solo un neumÃ¡tico: inflarlo, verificar que no tenga fugas y confirmar que estÃ© en buen estado. En Python, estas pruebas se automatizan utilizando la palabra claveÂ `assert`, que compara los resultados esperados con los reales.

## **Â¿QuÃ© son las pruebas de integraciÃ³n?**

Las pruebas de integraciÃ³n verifican que diferentes componentes de la aplicaciÃ³n funcionen en conjunto sin problemas. En el caso del mecÃ¡nico, serÃ­a comprobar que el neumÃ¡tico instalado en el coche funcione bien con el resto de las piezas del vehÃ­culo. En desarrollo de software, esto se traduce a verificar, por ejemplo, que el proceso de inicio de sesiÃ³n funcione correctamente, desde la entrada del usuario hasta la confirmaciÃ³n del acceso.

## **Â¿CÃ³mo Python nos ayuda a automatizar pruebas?**

Python ofrece herramientas para automatizar las pruebas, permitiendo ejecutar muchas validaciones rÃ¡pidamente sin intervenciÃ³n manual. A travÃ©s de pruebas automatizadas, podemos detectar errores que de otro modo podrÃ­an pasar desapercibidos y llegar a producciÃ³n, como un fallo en el cÃ¡lculo de una orden de compra. Esto es crÃ­tico para evitar situaciones como la que enfrentÃ³ CrowdStrike, donde un error no detectado en una actualizaciÃ³n paralizÃ³ aeropuertos.

```python
#tests.py
def calculate_total(products):
    total = 0
    for product in products:
        total += product["price"]
    return total

def test_calculate_total_with_empty_list():
    assert calculate_total([]) == 0

def test_calculate_total_with_single_product():
    products = [
        {
            "name": "Notebook", "price": 5
        }
    ]
    assert calculate_total(products) == 5

def test_calculate_total_with_multiple_product():
    products = [
        {
            "name": "Book", "price": 10
        },
        {
            "name": "Pen", "price": 2
        }
    ]
    assert calculate_total(products) == 12

if __name__ == "__main__":
    test_calculate_total_with_empty_list()
    test_calculate_total_with_single_product()
    test_calculate_total_with_multiple_product()
```

# InstalaciÃ³n y ConfiguraciÃ³n del Entorno de Pruebas

La creaciÃ³n de funciones y pruebas para el cÃ³digo que se va a producciÃ³n es clave para validar resultados correctamente. En Python, el uso de Unit Testing simplifica este proceso, permitiendo automatizar pruebas y hacerlas mÃ¡s legibles y eficientes, ademÃ¡s de integrarse fÃ¡cilmente con sistemas de Continuous Integration.

### **Â¿CÃ³mo mejorar la legibilidad de las pruebas con Unit Testing?**

Python incluye Unit Testing de forma nativa, proporcionando clases reutilizables para ejecutar pruebas de manera automÃ¡tica o manual. Esta herramienta no solo permite mejorar la legibilidad, sino tambiÃ©n identificar y solucionar errores rÃ¡pidamente, sin necesidad de depender deÂ `print`Â para verificar si las pruebas se estÃ¡n ejecutando.

### **Â¿CÃ³mo estructurar un proyecto de testing en Python?**

1. **SeparaciÃ³n de cÃ³digo y pruebas:**Â Coloca el cÃ³digo fuente en una carpetaÂ `src`Â y las pruebas en una carpetaÂ `test`.
2. **Entorno virtual:**Â Crea un entorno virtual para aislar dependencias del proyecto. Esto se hace conÂ `python -m venv env`  , lo que genera una carpeta con binarios y librerÃ­as solo para el proyec
3. **Uso de gitignore:**Â AÃ±ade un archivoÂ `.gitignore`Â para evitar que el entorno virtual y otros archivos no deseados se suban al repositorio.

### **Â¿CÃ³mo escribir y ejecutar pruebas con Unit Test?**

Para escribir pruebas, sigue estas buenas prÃ¡cticas:

- Crea un archivo de pruebas, comoÂ `test_calculator.py`, y empieza importando Unit Test.
- Define clases que hereden deÂ `unittest.TestCase`.
- Escribe mÃ©todos de prueba que validen funciones especÃ­ficas usandoÂ `assertEqual`Â para verificar resultados.

Ejemplo bÃ¡sico de prueba:

```python
#src/calculator.py
def add(a, b):
    return a + b

def subtract(a, b):
    return a - b

```

```python
#test/test_calculator.py
import unittest
from src.calculator import add, subtract

class TestCalculator(unittest.TestCase):
    def test_add(self):
        self.assertEqual(add(2, 3), 5)

    def test_subtract(self):
        self.assertEqual(subtract(10, 5), 5)

```

Ejecuta las pruebas conÂ `python -m unittest discover`Â para que Unit Testing encuentre y ejecute las pruebas automÃ¡ticamente. En nuestro caso: `python -m unittest discover -s test`

### **Â¿QuÃ© hacer cuando una prueba falla?**

Si una prueba falla, Unittest lo indica con una â€œFâ€, mostrando el error detallado, lo que facilita la depuraciÃ³n. Puedes forzar un fallo, por ejemplo, esperando que la suma deÂ `2 + 3`Â seaÂ `6`Â en lugar deÂ `5`, para ver cÃ³mo se comporta

## ğŸš€Â Reto

Agrega multiplicaciÃ³n y divisiÃ³n a calculadora y agrega pruebas unitarias, considera casos especÃ­ficos como la divisiÃ³n entre 0. 

https://github.com/platzi/python-testing/tree/2d5ac48dbcf401758ac0786befe0280cbb2015d2

# ğŸ”¹ Conceptos BÃ¡sicos de Unittest

# CÃ³mo Crear Pruebas Unitarias con UnitTest en Python

Las pruebas unitarias en Python son esenciales para asegurar el correcto funcionamiento del cÃ³digo. Utilizando la claseÂ `TestCase`Â de la bibliotecaÂ `UnitTest`, podemos estructurar pruebas de manera eficiente y limpiar recursos una vez que se han ejecutado. AdemÃ¡s, permite automatizar la validaciÃ³n de resultados y la captura de errores. Vamos a profundizar en cÃ³mo implementar estas pruebas y algunos mÃ©todos clave que facilitan este proceso.

## **Â¿CÃ³mo configurar las pruebas en Python con TestCase?**

El mÃ©todoÂ `setUp()`Â nos permite configurar elementos antes de que cada prueba se ejecute. Imagina que tienes cinco pruebas que requieren la misma preparaciÃ³n: en lugar de repetir la configuraciÃ³n, puedes ejecutarla una sola vez aquÃ­. Esto ahorra tiempo y esfuerzo al evitar la duplicaciÃ³n de cÃ³digo.

Por ejemplo:

- Puedes utilizarÂ `setUp()`Â para crear una base comÃºn de datos, abrir archivos, o preparar datos de entrada.
- Luego, cada prueba reutiliza esta configuraciÃ³n, asegurando que el entorno siempre estÃ© listo para las pruebas.

## **Â¿CÃ³mo limpiar despuÃ©s de una prueba?**

El mÃ©todoÂ `tearDown()`Â sirve para limpiar los recursos utilizados en la prueba. Supongamos que has creado cientos de archivos para una prueba, este mÃ©todo permite eliminarlos automÃ¡ticamente despuÃ©s de que la prueba finaliza, asegurando que el sistema no quede lleno de datos innecesarios.

Algunos ejemplos de cuÃ¡ndo usarlo:

- Eliminar archivos temporales creados durante las pruebas.
- Cerrar conexiones a bases de datos o liberar recursos del sistema.

## **Â¿CÃ³mo ejecutar pruebas y capturar errores?**

La claseÂ `TestCase`Â no solo organiza las pruebas, tambiÃ©n proporciona un mÃ©todo automÃ¡tico para ejecutar cada una de ellas. El mÃ©todoÂ `runTest()`Â gestiona la ejecuciÃ³n de las pruebas, captura los errores y valida que todo funcione correctamente. Este proceso automatiza la validaciÃ³n de resultados esperados y la identificaciÃ³n de fallos.

Por ejemplo:

- Si tienes una lista de pruebas, este mÃ©todo las ejecutarÃ¡ una por una, asegurando que todas se validen correctamente.
- AdemÃ¡s, capturarÃ¡ las excepciones que se lancen durante la ejecuciÃ³n.

## **Â¿CÃ³mo validar excepciones en las pruebas unitarias?**

Una situaciÃ³n comÃºn en las pruebas de una calculadora es manejar la divisiÃ³n por cero. La mejor prÃ¡ctica es lanzar una excepciÃ³n para evitar errores. Python permite validar que la excepciÃ³n se ha lanzado correctamente en las pruebas.

Pasos clave:

- Crear una prueba dondeÂ `b = 0`.
- UtilizarÂ `assertRaises()`Â para verificar que se ha lanzado la excepciÃ³nÂ `ValueError`.

# CÃ³mo usar el mÃ©todo setup en tests de Python

El uso del mÃ©todoÂ `setup`Â en los tests permite simplificar y evitar la duplicaciÃ³n de cÃ³digo en las pruebas. Al iniciar un test,Â `setup`Â se ejecuta automÃ¡ticamente, preparando el entorno para cada prueba de forma eficiente. En este caso, pasamos de un proyecto de calculadora a uno de una cuenta bancaria, y veremos cÃ³mo implementar pruebas unitarias para depÃ³sitos, retiros y consultas de saldo utilizandoÂ `setup`Â para optimizar el cÃ³digo.

```python
#src/bank_account.py
class BankAccount:
    def __init__(self, balance=0):
        self.balance = balance

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
        return self.balance

    def withdraw(self, amount):
        if amount > 0:
            self.balance -= amount
        return self.balance

    def get_balance(self):
        return self.balance
```

## **Â¿CÃ³mo implementar pruebas para depÃ³sitos en una cuenta bancaria?**

Primero, se crea la clase de test donde se probarÃ¡n los mÃ©todos de una cuenta bancaria. Para hacer un depÃ³sito, se debe instanciar una cuenta con un saldo inicial, realizar el depÃ³sito y luego validar que el saldo ha cambiado correctamente.

Pasos:

- Crear el archivoÂ `test_bank_account.py`.
- Instanciar una cuenta con saldo inicial.
- Probar que el mÃ©todo de depÃ³sito ajusta el saldo correctamente.

![image.png](attachment:960de2c0-a58e-4294-89d9-eb9cf2a9faf8:image.png)

## **Â¿CÃ³mo optimizar las pruebas con el mÃ©todo setup?**

El mÃ©todoÂ `setup`Â evita la creaciÃ³n repetitiva de instancias en cada test. Para lograr esto:

- Se crea una instancia de cuenta enÂ `setup`.
- La cuenta creada se comparte entre todas las pruebas usandoÂ `self`.

Esto simplifica las pruebas al evitar duplicar el cÃ³digo de instanciaciÃ³n en cada mÃ©todo de test.

## **Â¿CÃ³mo ejecutar las pruebas de retiro y consulta de saldo?**

Para las pruebas de retiro y consulta de saldo:

- El mÃ©todoÂ `withdraw`Â debe restar la cantidad del saldo y validar que el resultado sea correcto.
- El mÃ©todoÂ `get_balance`Â simplemente valida que el saldo actual coincida con lo esperado.

Estas pruebas se benefician del uso deÂ `setup`, ya que reutilizan la misma instancia de cuenta creada para cada prueba.

## **Â¿CÃ³mo ejecutar pruebas con salida mÃ¡s detallada?**

Al ejecutar las pruebas, es Ãºtil utilizar el comando con la opciÃ³nÂ `-b`Â para obtener una salida mÃ¡s detallada y visualizar exactamente quÃ© pruebas se estÃ¡n ejecutando y dÃ³nde estÃ¡n ubicadas en el cÃ³digo. Esto ayuda a depurar y tener un mejor control sobre el flujo de las pruebas.

```python
import unittest

from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000)

    def test_deposit(self):
        new_balance = self.account.deposit(500)
        assert new_balance == 1500

    def test_withdraw(self):
        new_balance = self.account.withdraw(200)
        assert new_balance == 800
    
    def test_get_balance(self):
        assert self.account.get_balance() == 1000
```

## ğŸš€Â Reto. **Â¿CÃ³mo crear pruebas para una nueva funcionalidad de transferencia?**

La tarea final consiste en agregar un mÃ©todo de transferencia a la claseÂ `BankAccount`, el cual debe:

- Permitir transferir saldo entre cuentas.
- Levantar una excepciÃ³n si el saldo no es suficiente para realizar la transferencia.

Luego, se deben crear dos pruebas unitarias:

1. Validar que la transferencia se realiza correctamente.
2. Validar que se lanza una excepciÃ³n cuando no hay saldo suficiente para completar la transferencia.

```python
#src/bank_account.py
class BankAccount:

    def __init__(self, balance=0):
        self.balance = balance

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
            return self.balance

        raise ValueError("Invalid deposit amount")

    def withdraw(self, amount):
        if 0 < amount <= self.balance:
            self.balance -= amount
            return self.balance

        raise ValueError("Invalid withdraw amount")

    def get_balance(self):
        return self.balance

    def transfer(self, account, amount):
        if 0 < amount <= self.balance:
            self.balance -= amount
            account.deposit(amount)
            return self.balance

        raise ValueError("Invalid transfer amount")

#tests/test_bank_account.py

from unittest import TestCase

from src.BankAccount import BankAccount

class BankAccountTests(TestCase):
    def setUp(self):
        self.account = BankAccount(1000)

    def test_deposit(self):
        self.account.deposit(500)
        assert self.account.get_balance() == 1500

    def test_withdraw(self):
        self.account.withdraw(500)
        assert self.account.get_balance() == 500

    def test_withdraw_fail(self):
        with self.assertRaises(ValueError):
            self.account.withdraw(1500)

    def test_get_balance(self):
        assert self.account.get_balance() == 1000

    def test_transfer(self):
        account2 = BankAccount(500)
        self.account.transfer(account2, 500)
        assert self.account.get_balance() == 500
        assert account2.get_balance() == 1000

    def test_transfer_fail(self):
        with self.assertRaises(ValueError):
            account2 = BankAccount(500)
            self.account.transfer(account2, 2000)
```

# Uso de tearDown para limpieza de Pruebas Unitarias en Python

El mÃ©todoÂ `teardown`Â es esencial para asegurar que nuestras pruebas no interfieran entre sÃ­, y se usa para limpiar cualquier recurso temporal al final de cada prueba. En este caso, lo hemos aplicado a nuestra cuenta bancaria, donde se registra un log cada vez que se realiza una acciÃ³n. Vamos a explorar cÃ³mo implementarlo correctamente y agregar funcionalidades de logging a nuestra cuenta de banco.

## **Â¿QuÃ© es el mÃ©todo teardown y cuÃ¡ndo lo usamos?**

El mÃ©todoÂ `teardown`Â se ejecuta al final de cada prueba, y es utilizado para limpiar recursos como archivos temporales o cerrar conexiones. En este caso, lo usamos para eliminar el archivo de logs que se genera durante nuestras pruebas de la cuenta bancaria. De esta manera, cada prueba se ejecuta en un entorno limpio, sin interferencias de pruebas anteriores.

## **Â¿CÃ³mo agregamos logging a la cuenta de banco?**

AÃ±adimos una funcionalidad de logging en el mÃ©todoÂ `init`, el cual se ejecuta cada vez que se crea una instancia de nuestra claseÂ `BankAccount`. El log incluye eventos como la creaciÃ³n de la cuenta, la consulta de saldo, y cuando se realizan depÃ³sitos o retiros. Esto se realiza a travÃ©s del mÃ©todoÂ `logTransaction`, que escribe el mensaje en un archivo de texto.

- Se define un archivo de log (`logFile`) al crear la cuenta.
- Cada vez que se realiza una transacciÃ³n o se consulta el saldo, se agrega una lÃ­nea al archivo.
- Para asegurar que el archivo de log se genera correctamente, creamos pruebas automatizadas.

```python
#src/bank_account.py
class BankAccount:
    def __init__(self, balance=0, log_file=None):
        self.balance = balance
        self.log_file = log_file
        self._log_transaction('Cuenta creada')

    def _log_transaction(self, message):
        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(f"{message}\n")

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
            self._log_transaction(f"Deposited {amount}. New balance: {self.balance}")
        return self.balance

    def withdraw(self, amount):
        if amount > 0:
            self.balance -= amount
            self._log_transaction(f"Withdrew {amount}. New balance: {self.balance}")
        return self.balance

    def get_balance(self):
        self._log_transaction(f"Checked balance. Current balance: {self.balance}")
        return self.balance
```

## **Â¿CÃ³mo validamos la existencia del archivo de log?**

En nuestras pruebas, verificamos si el archivo de log se crea exitosamente. Utilizamos la funciÃ³nÂ `os.path.exists`Â para validar su existencia y asegurarnos de que nuestras pruebas estÃ¡n funcionando correctamente.

```python
    #tests/test_bank_account.py
    def test_transaction_log(self):
        self.account.deposit(500)
        assert os.path.exists("transaction_log.txt")

```

## **Â¿CÃ³mo usamos el teardown para limpiar archivos?**

ElÂ `teardown`Â nos permite eliminar el archivo de log despuÃ©s de cada prueba para que no interfiera con otras. Implementamos una funciÃ³n que, si el archivo existe, lo borra utilizandoÂ `os.remove`. Esto asegura que las pruebas se ejecutan en un entorno limpio y los logs no se acumulan entre pruebas.

```python
#tests/test_bank_account.py
def tearDown(self) -> None:
    if os.path.exists(self.account.log_file):
        os.remove(self.account.log_file)

```

## **Â¿CÃ³mo probamos que los logs contienen la informaciÃ³n correcta?**

AdemÃ¡s de verificar que el archivo existe, es fundamental asegurarnos de que el contenido del archivo sea correcto. Para ello, creamos un mÃ©todo que cuenta las lÃ­neas del archivo (`countLines`). Luego, en nuestras pruebas, validamos que el nÃºmero de lÃ­neas corresponde al nÃºmero de transacciones realizadas.

- Contamos las lÃ­neas despuÃ©s de crear la cuenta (debe haber una lÃ­nea).
- Hacemos un depÃ³sito y volvemos a contar las lÃ­neas (debe haber dos lÃ­neas).
- Si no limpiÃ¡ramos el archivo conÂ `teardown`, el nÃºmero de lÃ­neas serÃ­a incorrecto.

```python
#tests/test_bank_account.py
import unittest, os

from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000, log_file="transaction_log.txt")

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)

    def _count_lines(self, filename): # al no empezar por test testcase no lo reconoce como test
        with open(filename, "r") as f:
            return len(f.readlines())

    def test_deposit(self):
        new_balance = self.account.deposit(500)
        assert new_balance == 1500

    def test_withdraw(self):
        new_balance = self.account.withdraw(200)
        assert new_balance == 800

    def test_get_balance(self):
        assert self.account.get_balance() == 1000

    def test_transaction_log(self):
        self.account.deposit(500)
        assert os.path.exists("transaction_log.txt")

    def test_count_transactions(self):
        assert self._count_lines(self.account.log_file) == 1
        self.account.deposit(500)
        assert self._count_lines(self.account.log_file) == 2
```

## ğŸš€Â Reto. **Â¿CÃ³mo crear una nueva funcionalidad de logging para transferencias fallidas?**

El siguiente reto es agregar una funcionalidad para registrar un log cuando alguien intente hacer una transferencia sin saldo disponible. El log debe incluir un mensaje indicando la falta de fondos, y tambiÃ©n se deben crear pruebas que validen que este log se genera correctamente.

- Se debe registrar el intento fallido en el archivo de log.
- Crear una prueba para asegurarse de que el mensaje â€œNo tiene saldo disponibleâ€ aparece en el log.
- UtilizarÂ `teardown`Â para limpiar el archivo al finalizar cada prueba.

```python
# src/bank_account.py
class BankAccount:
    def __init__(self, balance = 0, log_file = None):
        self.balance = balance
        self.log_file = log_file
        self._log_transaction("Cuenta creada")

    def _log_transaction(self,message):
        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(f"{message}\n")

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
            self._log_transaction(f"Cantidad depositada {amount}. Nuevo balance: {self.balance}")
        return self.balance
    
    def withdraw(self, amount):
        if amount > 0:
            self.balance -= amount
            self._log_transaction(f"Retiro {amount}. Nuevo balance: {self.balance}")
        return self.balance
    
    def transfer(self, amount, target_account):
        if amount > 0 and self.balance >= amount:
            self.balance -= amount
            target_account.deposit(amount)
            self._log_transaction(f"Transferencia de {amount} realizada con Ã©xito. Nuevo balance: {self.balance}")
        else:
            error_message = f"Transferencia fallida por monto {amount}. Saldo disponible {self.balance}"
            self._log_transaction(error_message)
            raise ValueError("No tiene saldo disponible")
        return self.balance
        

    def get_balance(self):
        self._log_transaction(f"Revision de balance. Balance actual {self.balance}")
        return self.balance

# test/bank_account.py
import unittest
import os

from src.bank_account import BankAccount

class BankAccountTest(unittest.TestCase):
    
    def setUp(self) -> None:
        self.account = BankAccount(balance = 1000, log_file = "transaction_log.txt")
        self.target_account = BankAccount(balance=500)

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)
            
    def _count_lines(self, filename):
        with open(filename, "r") as f:
		            return len(f.readlines())
		        
		def _log_contains(self, message):
			with open(self.log_file, "r") as f:
			  return any(message in line for line in f.readlines())
		
    def test_deposit(self):
        new_balance = self.account.deposit(500)
        assert new_balance == 1500
    
    def test_withdraw(self):
        new_balance = self.account.withdraw(500)
        assert new_balance == 500
    
    def test_transfer(self):
        self.account.transfer(20000, self.target_account)
        self.assertEqual(self.account.get_balance(), 800)
        self.assertEqual(self.target_account.get_balance(), 700)
 
    def test_transfer_fails_insufficient_funds(self):
		    with self.assertRaises(ValueError):
		      self.account.transfer(20000, self.target_account)

        self.assertTrue(self._log_contains("Transferencia fallida por monto 20000"))

    def test_get_balance(self):
        assert self.account.get_balance() == 1000

    def test_transaction_log(self):
        self.account.deposit(500)
        assert os.path.exists("transaction_log.txt")
    
    def test_count_transactions(self):
        assert self._count_lines(self.account.log_file) == 1
        self.account.deposit(500)
        assert self._count_lines(self.account.log_file) == 2
```

# CÃ³mo validar excepciones y estructuras de datos con Unittest en Python

UnitTest nos proporciona una amplia gama de mÃ©todos de aserciÃ³n que mejoran la forma en que validamos nuestras pruebas. En esta clase, hemos explorado algunos de ellos y cÃ³mo utilizarlos en diferentes escenarios.

## **Â¿CÃ³mo se usa el assertEqual en Unit Test?**

El mÃ©todoÂ `assertEqual`Â compara dos valores para verificar si son iguales. Acepta dos parÃ¡metros para comparar y opcionalmente un mensaje personalizado que se mostrarÃ¡ en la terminal si la prueba falla. Este mÃ©todo se integra bien con los editores, permitiendo ejecutar y depurar pruebas de manera eficiente.

- ParÃ¡metros: valor esperado, valor obtenido, mensaje de error (opcional)
- Uso tÃ­pico: Validar igualdad de nÃºmeros, cadenas, o cualquier otro objeto comparable.

```python
#tests/test_bank_account.py
import unittest, os

from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000, log_file="transaction_log.txt")

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)

    def _count_lines(self, filename):
        with open(filename, "r") as f:
            return len(f.readlines())

    def test_deposit(self):
        new_balance = self.account.deposit(500)
        self.assertEqual(new_balance, 1500, "El balance no es igual")

    def test_withdraw(self):
        new_balance = self.account.withdraw(200)
        self.assertEqual(new_balance, 800, "El balance no es igual")

    def test_get_balance(self):
        self.assertEqual(self.account.get_balance(), 1000)

    def test_transaction_log(self):
        self.account.deposit(500)
        self.assertTrue(os.path.exists("transaction_log.txt"))

    def test_count_transactions(self):
        assert self._count_lines(self.account.log_file) == 1
        self.account.deposit(500)
        assert self._count_lines(self.account.log_file) == 2
```

## **Â¿QuÃ© otros mÃ©todos de aserciÃ³n existen en Unit Test?**

AdemÃ¡s deÂ `assertEqual`, Unit Test incluye muchos otros mÃ©todos de aserciÃ³n Ãºtiles:

- `assertTrue`: Verifica que una expresiÃ³n sea verdadera. No compara valores, solo evalÃºa si una condiciÃ³n es cierta.
- `assertRaises`: Valida que se lance una excepciÃ³n especÃ­fica dentro de un bloque de cÃ³digo, utilizando la palabra claveÂ `with`Â como contexto.
- `assertIn`Â yÂ `assertNotIn`: Comprueban si un elemento estÃ¡ o no estÃ¡ dentro de una secuencia, como una lista o un conjunto.

## **Â¿CÃ³mo se manejan excepciones en Unit Test?**

ConÂ `assertRaises`, se puede verificar que una excepciÃ³n se lance correctamente. Este mÃ©todo es especialmente Ãºtil para manejar errores esperados, como cuando un usuario no tiene suficientes fondos para completar una transferencia.

- Se utiliza conÂ `with`Â para capturar la excepciÃ³n dentro de un bloque de cÃ³digo.
- Ejemplo: Capturar unÂ `ValueError`Â al pasar un argumento no vÃ¡lido a una funciÃ³n.

## **Â¿CÃ³mo comparar listas, diccionarios y sets en Unit Test?**

Unit Test ofrece mÃ©todos para comparar estructuras de datos mÃ¡s complejas:

- `assertDictEqual`: Compara dos diccionarios.
- `assertSetEqual`: Compara dos sets para validar que contengan los mismos elementos, independientemente del orden.
- Estos mÃ©todos tambiÃ©n cuentan con variantes negativas, comoÂ `assertNotEqual`, para validar desigualdades.

```python
#tests/tests_all_asserts.py
import unittest

class AllAssertsTests(unittest.TestCase):

    def test_assert_equal(self):
        self.assertEqual(10, 10)
        self.assertEqual("Hola", "Hola")

    def test_assert_true_or_false(self):
        self.assertTrue(True)
        self.assertFalse(False)

    def test_assert_raises(self):
        with self.assertRaises(ValueError):
            int("no_soy_un_numero")

    def test_assert_in(self):
        self.assertIn(10, [2, 4, 5, 10])
        self.assertNotIn(5, [2, 4, 10])

    def test_assert_dicts(self):
        user = {"first_name": "Luis", "last_name": "Martinez"}
        self.assertDictEqual(
            {"first_name": "Luis", "last_name": "Martinez"},
            user
        )
        self.assertSetEqual(
            {1, 2, 3},
            {1, 2, 3}
        )
```

# Control de pruebas unitarias con unittest.skip en Python

En el desarrollo de software, es comÃºn enfrentarse a situaciones donde las pruebas unitarias no pueden ejecutarse por cambios o desarrollos en curso. En estos casos, comentar el cÃ³digo de las pruebas no es la mejor prÃ¡ctica. Afortunadamente, Python yÂ `unittest`Â ofrecen decoradores que nos permiten omitir pruebas temporalmente, sin comprometer el flujo de trabajo ni la integridad del proyecto. AquÃ­ aprenderemos cÃ³mo usar decoradores comoÂ `@skip`,Â `@skipIf`Â yÂ `@expectedFailure`Â para manejar estos casos de manera eficiente.

## **Â¿CÃ³mo utilizar el decorador @skip?**

El decoradorÂ `@skip`Â se utiliza cuando sabemos que una prueba no deberÃ­a ejecutarse temporalmente. Esto es Ãºtil si estamos trabajando en un feature que aÃºn no estÃ¡ completo y, por lo tanto, las pruebas no tienen sentido. Al aplicarÂ `@skip`, podemos evitar la ejecuciÃ³n de la prueba y aÃºn asÃ­ tener visibilidad de que estÃ¡ pendiente de ser corregida.

- Aplicamos el decorador con una razÃ³n clara.
- Cuando ejecutamos las pruebas, en el reporte se indicarÃ¡ que la prueba fue saltada.

### Ejemplo de uso:

```python
@unittest.skip("Trabajo en progreso, serÃ¡ habilitada nuevamente.")
def test_skip_example(self):
    self.assertEqual("hola", "chau")

```

## **Â¿CuÃ¡ndo aplicar @skipIf?**

El decoradorÂ `@skipIf`Â es Ãºtil cuando queremos omitir una prueba bajo una condiciÃ³n especÃ­fica. Esto es comÃºn cuando nuestras pruebas dependen del entorno, como servidores diferentes o configuraciones especÃ­ficas.

- Requiere una condiciÃ³n y una razÃ³n para ser aplicado.
- Se ejecutarÃ¡ solo si la condiciÃ³n es verdadera.

### Ejemplo de uso:

```python
server = "server_b"
@unittest.skipIf(server == "server_a", "Saltada porque no estamos en el servidor correcto.")
def test_skipif_example(self):
    self.assertEqual(1000, 100)

```

## **Â¿QuÃ© hace el decorador @expectedFailure?**

Este decorador se usa cuando sabemos que una prueba fallarÃ¡ debido a un cambio en la lÃ³gica del negocio o un bug conocido, pero queremos mantener la prueba visible en el reporte de pruebas.

- Es Ãºtil para reflejar fallos esperados sin interferir con el flujo de integraciÃ³n continua.
- El reporte mostrarÃ¡ que la prueba fallÃ³ como se esperaba.

### Ejemplo de uso:

```python
@unittest.expectedFailure
def test_expected_failure_example(self):
    self.assertEqual(100, 150)

```

## **Â¿CÃ³mo aplicar @skipUnless en casos avanzados?**

El decoradorÂ `@skipUnless`Â es valioso cuando queremos ejecutar una prueba solo si se cumple una condiciÃ³n. Un ejemplo clÃ¡sico es validar si un servicio externo, como una API, estÃ¡ disponible antes de ejecutar la prueba.

- Es ideal para escenarios donde dependemos de recursos externos, como APIâ€™s de terceros.

### Ejemplo de uso:

```python
@unittest.skipUnless(api_available(), "API no disponible.")
def test_skipunless_example(self):
    self.assertEqual(get_currency_rate("USD"), 1.0)

```

## **Â¿CuÃ¡ndo utilizar estos decoradores en desarrollo colaborativo?**

El uso de decoradores comoÂ `@skip`,Â `@skipIf`,Â `@expectedFailure`Â yÂ `@skipUnless`Â en un equipo de desarrollo asegura que las pruebas no interfieran en el flujo de trabajo, mientras mantienen la visibilidad de las pruebas pendientes. Es esencial en entornos de integraciÃ³n continua (CI), donde se busca que las pruebas no bloqueen el desarrollo, pero sin ignorarlas por completo.

```python
#tests/tests_all_asserts.py
import unittest

SERVER="server_b"

class AllAssertsTests(unittest.TestCase):

    def test_assert_equal(self):
        self.assertEqual(10, 10)
        self.assertEqual("Hola", "Hola")

    def test_assert_true_or_false(self):
        self.assertTrue(True)
        self.assertFalse(False)

    def test_assert_raises(self):
        with self.assertRaises(ValueError):
            int("no_soy_un_numero")

    def test_assert_in(self):
        self.assertIn(10, [2, 4, 5, 10])
        self.assertNotIn(5, [2, 4, 10])

    def test_assert_dicts(self):
        user = {"first_name": "Luis", "last_name": "Martinez"}
        self.assertDictEqual(
            {"first_name": "Luis", "last_name": "Martinez"},
            user
        )
        self.assertSetEqual(
            {1, 2, 3},
            {1, 2, 3}
        )

    @unittest.skip("Trabajo en progreso, serÃ¡ habilitada nuevamente")
    def test_skip(self):
        self.assertEqual("hola", "chao")

    @unittest.skipIf(SERVER == "server_b", "Saltado porque no estamos en el servidor")
    def test_skip_if(self):
        self.assertEqual(100, 100)

    @unittest.expectedFailure
    def test_expected_failure(self):
        self.assertEqual(100, 150)
```

# ğŸ”¹Â OrganizaciÃ³n y GestiÃ³n de Pruebas

# CÃ³mo organizar y ejecutar pruebas en Python con UnitTest

Cuando estamos desarrollando en Python, ejecutar todas las pruebas desde la terminal es comÃºn en entornos de desarrollo. Sin embargo, en producciÃ³n o integraciÃ³n continua, este enfoque puede no ser ideal, especialmente cuando solo queremos ejecutar pruebas especÃ­ficas o tener un mejor control sobre cÃ³mo organizamos y ejecutamos estas pruebas. Python y su mÃ³dulo Unit Test nos ofrecen herramientas como las suites de pruebas para modularizar y seleccionar quÃ© pruebas ejecutar.

## **Â¿CÃ³mo ejecutar pruebas especÃ­ficas en Python?**

Para ejecutar pruebas especÃ­ficas, podemos usar el comandoÂ `discover`Â del subcomando Unit Test. Este comando busca automÃ¡ticamente todas las pruebas dentro de una carpeta y las agrupa en una suite. Sin embargo, este enfoque no es siempre ideal para entornos locales, donde podrÃ­amos querer ejecutar solo ciertas pruebas.

### Â¿QuÃ© son las suites de pruebas?

Una suite de pruebas es un grupo de pruebas que podemos ejecutar juntas. En proyectos pequeÃ±os, generalmente tenemos una sola suite, pero a medida que crece el proyecto, modularizar las pruebas por categorÃ­as o caracterÃ­sticas es recomendable. Por ejemplo, podrÃ­amos tener una suite para pruebas de calculadora y otra para pruebas de banco.

## **Â¿CÃ³mo crear y ejecutar una suite de pruebas manualmente?**

1. **Crear una suite manualmente**:
    - Creamos un archivo nuevo, por ejemplo,Â `test_suites.py`.
    - ImportamosÂ `UnitTest`Â y definimos una suite conÂ `suite = unittest.TestSuite()`.
    - Agregamos pruebas a la suite usandoÂ `suite.addTest()`.
2. **Agregar pruebas especÃ­ficas**:
    - Podemos importar pruebas existentes y aÃ±adirlas a la suite. Por ejemplo, si ya tenemos una prueba llamadaÂ `test_deposit`, podemos agregarla a la suite conÂ `suite.addTest(bankAccountTests('test_deposit'))`.
3. **Ejecutar las suites con un runner**:
    - Para ejecutar una suite, necesitamos un runner. Python ofrece varios tipos de runners. Un ejemplo serÃ­a elÂ `TextTestRunner`, que se usa comÃºnmente en la terminal.
    - El cÃ³digo bÃ¡sico para ejecutar la suite serÃ­a:
        
        ```python
        runner = unittest.TextTestRunner()
        runner.run(suite)
        
        ```
        

```python
#tests/test_suites.py
import unittest

#from tests.test_bank_account import BankAccountTests
from test_bank_account import BankAccountTests

def bank_account_suite():
    suite = unittest.TestSuite()
    suite.addTest(BankAccountTests("test_deposit"))
    suite.addTest(BankAccountTests("test_withdraw"))
    return suite

if __name__ == "__main__":
    runner = unittest.TextTestRunner()
    runner.run(bank_account_suite())
```

## **Â¿CÃ³mo configurar Visual Studio Code para ejecutar pruebas?**

Visual Studio Code facilita la ejecuciÃ³n de pruebas con su interfaz grÃ¡fica. Podemos configurar un runner y seleccionar quÃ© pruebas ejecutar directamente desde el editor.

1. **Configurar las pruebas en Visual Studio Code**:
    - En la configuraciÃ³n, seleccionamos Unit Test como el framework de pruebas y especificamos la carpeta donde se encuentran las pruebas.
    - Visual Studio Code lista automÃ¡ticamente las pruebas, permitiÃ©ndonos ejecutarlas con un solo clic.
2. **Ejecutar pruebas individuales**:
    - Al hacer clic en una prueba especÃ­fica, podemos ver su resultado inmediatamente, ya sea que la prueba haya pasado, fallado o se haya omitido.

## **Â¿CÃ³mo solucionar errores comunes al ejecutar pruebas?**

Durante la ejecuciÃ³n de las pruebas, es comÃºn encontrarse con errores como â€œmÃ³dulo no encontradoâ€. Estos errores se pueden solucionar asegurÃ¡ndonos de que las carpetas contienen archivosÂ `__init__.py`Â y configurando correctamente elÂ `PYTHONPATH`Â para que Python encuentre todos los mÃ³dulos necesarios.

En nuestro caso: `PYTHONPATH=. python tests/test_suites.py`

## **Â¿CÃ³mo ejecutar pruebas desde la terminal?**

Podemos ejecutar una prueba especÃ­fica directamente desde la terminal usando la siguiente estructura de comando:

```bash
python -m unittest tests.test_calculator.CalculatorTest.test_add

```

Esto ejecuta Ãºnicamente la pruebaÂ `test_sum`Â de la claseÂ `CalculatorTest`.

# Mejores prÃ¡cticas para organizar y nombrar pruebas en Python

Nombrar pruebas correctamente es clave para el Ã©xito en equipo, facilitando la comprensiÃ³n del cÃ³digo y la colaboraciÃ³n efectiva. Aunque no es obligatorio, tener un formato claro para las pruebas es muy beneficioso.

## **Â¿CÃ³mo definir el formato de los nombres de las pruebas?**

- Todos los tests deben agruparse en clases, cada una relacionada con una clase de tu proyecto. Por ejemplo, si tienes una clase llamadaÂ `BankAccount`, la clase de prueba deberÃ­a llamarseÂ `BankAccountTest`.
- Cada prueba debe comenzar conÂ `test_`, para que las herramientas de testing la identifiquen fÃ¡cilmente.
- El siguiente elemento en el nombre debe ser el mÃ©todo que estÃ¡s probando. Si es un mÃ©todoÂ `deposit`, el nombre serÃ­aÂ `test_deposit_`.

## **Â¿CÃ³mo estructurar el escenario de la prueba?**

- DespuÃ©s del mÃ©todo, aÃ±ade el escenario. Esto se refiere a los valores o parÃ¡metros que usas en la prueba. Por ejemplo, en el caso de un valor positivo en un depÃ³sito, el escenario serÃ­aÂ `positive_amount`.

## **Â¿CÃ³mo describir el resultado esperado?**

- Para finalizar el nombre, indica el resultado esperado. Si el depÃ³sito incrementa el saldo, aÃ±ade algo comoÂ `increase_balance`. AsÃ­, un nombre de prueba completo serÃ­a:Â `test_deposit_positive_amount_increase_balance`.

## **Â¿Por quÃ© es Ãºtil este formato?**

- Permite a cualquier miembro del equipo entender el propÃ³sito de la prueba sin revisar el cÃ³digo completo.
- Facilita el mantenimiento del cÃ³digo y el soporte, ya que con solo leer el nombre, se entiende el objetivo de la prueba.

## ğŸš€Â Reto. **Â¿QuÃ© reto se propone para mejorar las pruebas actuales?**

- Refactoriza las pruebas que has creado, probando diferentes escenarios y resultados posibles.
- Imagina nuevas circunstancias para probar el cÃ³digo.

```python
#test_bank_account.py 
import unittest, os

from src.exceptions import InsufficientFundsError
from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000, log_file="transaction_log.txt")

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)

    def _count_lines(self, filename):
        with open(filename, "r") as f:
            return len(f.readlines())

    def test_deposit_increases_balance_by_deposit_amount(self):
        new_balance = self.account.deposit(500)
        self.assertEqual(new_balance, 1500, "El balance no es igual")

    def test_withdraw_decreases_balance_by_withdraw_amount(self):
        new_balance = self.account.withdraw(200)
        self.assertEqual(new_balance, 800, "El balance no es igual")

    def test_get_balance_returns_current_balance(self):
        self.assertEqual(self.account.get_balance(), 1000)

    def test_deposit_logs_transaction(self):
        self.account.deposit(500)
        self.assertTrue(os.path.exists("transaction_log.txt"))

    def test_withdraw_logs_each_transaction(self):
        self.assertEqual(self._count_lines(self.account.log_file), 1)
        self.account.deposit(500)
        self.assertEqual(self._count_lines(self.account.log_file), 2)

    def test_withdraw_raises_error_when_insufficient_funds(self):
        with self.assertRaises(InsufficientFundsError):
            self.account.withdraw(2000)
```

# ğŸ”¹Â TÃ©cnicas Avanzadas en Pruebas Unitarias

# Mocking de APIs externas en Python con unittest

La simulaciÃ³n de servicios externos es crucial en proyectos de software para garantizar que las pruebas no dependan de APIs externas. Para lograrlo, utilizamos los Mocks, que permiten evitar las llamadas reales a servicios y, en cambio, retornan respuestas controladas en nuestras pruebas. En este caso, aprenderemos a mockear una API de geolocalizaciÃ³n y a realizar pruebas efectivas.

## **Â¿QuÃ© es un Mock y cÃ³mo nos ayuda?**

Un Mock es una herramienta que nos permite simular comportamientos de funciones o servicios externos. En lugar de ejecutar una llamada real a una API, podemos definir una respuesta predefinida, lo que permite:

- Evitar depender de servicios externos en pruebas.
- Acelerar la ejecuciÃ³n de las pruebas.
- Controlar los resultados esperados.

## **Â¿CÃ³mo integramos una API externa en Python?**

Primero, se configura una funciÃ³n que recibe la IP del cliente y devuelve la ubicaciÃ³n mediante una API de terceros. Para hacer esto:

1. Se instala la librerÃ­aÂ `requests`Â conÂ `pip install requests`.
2. Se crea un archivoÂ `api_client.py`Â donde conectamos con la API utilizandoÂ `requests.get`.
3. Al recibir la respuesta, se convierte el resultado a JSON para obtener la informaciÃ³n de paÃ­s, ciudad y regiÃ³n.

```python
#src/api_client.py
import requests

def get_location(ip):
    url = f"https://freeipapi.com/api/json/{ip}"
    response = requests.get(url)
    response.raise_for_status()
    data = response.json()
    return {
        "country": data["countryName"],
        "region": data["regionName"],
        "city": data["cityName"],
    }

if __name__ == "__main__":
    print(get_location("8.8.8.8"))
```

## **Â¿CÃ³mo probamos sin hacer llamadas reales?**

El problema principal de las pruebas de integraciones con APIs es que pueden requerir tiempo, ya que las respuestas dependen de factores externos. Para evitar esto, se usan Mocks. A travÃ©s del decoradorÂ `@patch`Â deÂ `unittest.mock`, podemos interceptar la llamada a la API y retornar datos predefinidos.

Pasos a seguir:

- Decorar la funciÃ³n de prueba conÂ `@patch`.
- Simular el valor retornado usandoÂ `mock.return_value`Â para definir quÃ© debe devolver la llamada a la API.
- Definir tanto el cÃ³digo de estado como el contenido del JSON que esperamos recibir.

```python
#tests/test_api_client.py
import unittest
from src.api_client import get_location
from unittest.mock  import patch

class ApiClientTests(unittest.TestCase):

    @patch('src.api_client.requests.get')
    def test_get_location_returns_expected_data(self, mock_get):
        mock_get.return_value.status_code = 200
        mock_get.return_value.json.return_value = {
            "countryName": "USA",
            "regionName": "FLORIDA",
            "cityName": "MIAMI",
        }
        result = get_location("8.8.8.8")
        self.assertEqual(result.get("country"), "USA")
        self.assertEqual(result.get("region"), "FLORIDA")
        self.assertEqual(result.get("city"), "MIAMI")

        mock_get.assert_called_once_with("https://freeipapi.com/api/json/8.8.8.8")
```

## **Â¿CÃ³mo validar que nuestra simulaciÃ³n funciona correctamente?**

AdemÃ¡s de simular respuestas, debemos asegurarnos de que las pruebas validen correctamente los llamados. Se puede usarÂ `assertCalledOnceWith`Â para garantizar que la URL y los parÃ¡metros pasados son los correctos.

# Uso de Side Effects en Mocking con Python

Mock nos permite simular comportamientos variables, una herramienta Ãºtil cuando queremos probar cÃ³mo reacciona nuestro cÃ³digo ante diferentes escenarios sin modificar el entorno real. Uno de los usos mÃ¡s poderosos es el â€œside effectâ€, que nos ayuda a hacer que un mÃ©todo falle en un caso y funcione en otro. Esto es clave para manejar errores temporales, como en el caso de una API de pagos que rechaza una tarjeta incorrecta, pero acepta una correcta en un segundo intento.

## **Â¿CÃ³mo se define un â€œside effectâ€ en Mock?**

El â€œside effectâ€ en Mock nos permite modificar el comportamiento de un mÃ©todo en distintas llamadas. Se define como una lista de comportamientos, donde cada elemento de la lista corresponde al resultado de una llamada especÃ­fica. Esto permite:

- Simular fallos de manera controlada, como lanzar excepciones especÃ­ficas en las pruebas.
- Probar el cÃ³digo bajo diferentes condiciones sin interactuar con los servicios externos.

## **Â¿CÃ³mo se maneja un error y una respuesta exitosa en pruebas unitarias?**

En una prueba unitaria con Mock, podemos definir comportamientos variables. Por ejemplo, para simular una excepciÃ³n, usamos la estructuraÂ `side_effect`, donde la primera llamada lanza un error y la segunda retorna una respuesta exitosa. Esto permite cubrir ambos casos sin necesidad de realizar un request real.

- Definimos el primer comportamiento con una excepciÃ³n.
- Luego, para el segundo comportamiento, usamosÂ `Mock`Â para devolver un objeto con los valores que esperamos, simulando una respuesta exitosa.

## **Â¿QuÃ© mÃ©todos auxiliares facilita Mock?**

Mock facilita mÃ©todos comoÂ `raiseException`, que lanza una excepciÃ³n especÃ­fica, yÂ `mock`, que permite crear objetos personalizados. Estos objetos pueden tener parÃ¡metros configurables comoÂ `status_code`Â y devolver datos especÃ­ficos al llamar mÃ©todos comoÂ `JSON`. Este tipo de pruebas es crucial para validar la resiliencia del software ante errores temporales.

```python
#tests/test_api_client.py
import unittest, requests
import unittest.mock
from src.api_client import get_location
from unittest.mock import patch

class ApiClientTests(unittest.TestCase):

    @patch("src.api_client.requests.get")
    def test_get_location_returns_expected_data(self, mock_get):
        mock_get.return_value.status_code = 200
        mock_get.return_value.json.return_value = {
            "countryName": "USA",
            "regionName": "FLORIDA",
            "cityName": "MIAMI",
        }
        result = get_location("8.8.8.8")
        self.assertEqual(result.get("country"), "USA")
        self.assertEqual(result.get("region"), "FLORIDA")
        self.assertEqual(result.get("city"), "MIAMI")

        mock_get.assert_called_once_with("https://freeipapi.com/api/json/8.8.8.8")

    @patch("src.api_client.requests.get")
    def test_get_location_returns_side_effect(self, mock_get):
        mock_get.side_effect = [
            requests.exceptions.RequestException("Service Unavailable"),
            unittest.mock.Mock(
                status_code=200,
                json=lambda: {
                    "countryName": "USA",
                    "regionName": "FLORIDA",
                    "cityName": "MIAMI",
                },
            ),
        ]

        with self.assertRaises(requests.exceptions.RequestException):
            get_location("8.8.8.8")

        result = get_location("8.8.8.8")
        self.assertEqual(result.get("country"), "USA")
        self.assertEqual(result.get("region"), "FLORIDA")
        self.assertEqual(result.get("city"), "MIAMI")
```

**Nota:** 

En este test, la **lambda** se utiliza dentro de `json=lambda: { ... }` para definir el comportamiento del mÃ©todo `.json()` en el segundo mock de `requests.get`.

**Â¿Por quÃ© usar una lambda en lugar de un diccionario directamente?**

Si se escribiera directamente asÃ­:

```python
json={"countryName": "USA", "regionName": "FLORIDA", "cityName": "MIAMI"}

```

el diccionario quedarÃ­a almacenado como un **atributo estÃ¡tico** del mock. Esto significa que cualquier modificaciÃ³n accidental en el cÃ³digo podrÃ­a afectar su valor.

En cambio, usando una **lambda**:

```python
json=lambda: { "countryName": "USA", "regionName": "FLORIDA", "cityName": "MIAMI" }

```

- Se asegura de que **cada vez que se llame `mock.json()`**, se genere un **nuevo diccionario**, evitando efectos colaterales.
- Esto simula de forma mÃ¡s realista el comportamiento de `requests.Response.json()`, que devuelve una nueva estructura de datos cada vez que se llama.

**ExplicaciÃ³n del cÃ³digo**

```python
@patch("src.api_client.requests.get")
def test_get_location_returns_side_effect(self, mock_get):

```

- Se usa `@patch` para **reemplazar `requests.get` por un mock** dentro del test.

```python
mock_get.side_effect = [
    requests.exceptions.RequestException("Service Unavailable"),
    unittest.mock.Mock(
        status_code=200,
        json=lambda: {
            "countryName": "USA",
            "regionName": "FLORIDA",
            "cityName": "MIAMI",
        },
    ),
]

```

- `mock_get.side_effect` define **una secuencia de respuestas simuladas** para `requests.get`:
    1. Primero, lanza una `RequestException` simulando que el servicio estÃ¡ caÃ­do.
    2. Luego, devuelve un mock que simula una respuesta exitosa con un cÃ³digo `200` y un mÃ©todo `.json()` que devuelve los datos esperados.

```python
with self.assertRaises(requests.exceptions.RequestException):
    get_location("8.8.8.8")

```

- Se espera que el primer intento **genere una excepciÃ³n** porque la API estÃ¡ "no disponible".

```python
result = get_location("8.8.8.8")
self.assertEqual(result.get("country"), "USA")
self.assertEqual(result.get("region"), "FLORIDA")
self.assertEqual(result.get("city"), "MIAMI")

```

- La segunda llamada devuelve el mock con la respuesta simulada.
- Se verifica que los datos obtenidos sean los esperados.

El uso de **lambda en `json=lambda: {...}`** garantiza que cada llamada a `.json()` devuelva un **nuevo objeto**, simulando el comportamiento real de `requests.Response.json()`.

## ğŸš€Â Reto. **Â¿CÃ³mo integrar validaciones adicionales en las pruebas?**

Para reforzar las pruebas, puedes agregar validaciones adicionales, como simular el envÃ­o de una IP invÃ¡lida. En este caso, si la IP es incorrecta, se debe lanzar un error, mientras que si es vÃ¡lida, debe retornar los datos de geolocalizaciÃ³n. Esto se implementa agregando mÃ¡s casos en la lista de side effects, cubriendo asÃ­ todas las situaciones posibles.

```python
#src/api_client.py
import requests

def get_location(ip):
    url = f"https://freeipapi.com/api/json/{ip}"
    response = requests.get(url)
    
    # Manejo de errores HTTP
    if response.status_code != 200:
        raise ValueError(f"API error: {response.status_code}")
    
    data = response.json()
    
    # Manejo de respuesta con error
    if "error" in data:
        raise ValueError(f"Invalid IP address: {data['error']}")
    
    return {
        "country": data.get("countryName", "Unknown"),
        "region": data.get("regionName", "Unknown"),
        "city": data.get("cityName", "Unknown"),
    }

if __name__ == "__main__":
    print(get_location("8.8.8.8"))

```

```python
# tests/test_api_client.py
import unittest
from unittest.mock import patch
import requests
from src.api_client import get_location

class ApiClientTests(unittest.TestCase):

    @patch('src.api_client.requests.get')
    def test_get_location_returns_expected_data(self, mock_get):
        mock_get.return_value.status_code = 200
        mock_get.return_value.json.return_value = {
            "countryName": "USA",
            "regionName": "FLORIDA",
            "cityName": "MIAMI",
        }
        result = get_location("8.8.8.8")
        self.assertEqual(result.get("country"), "USA")
        self.assertEqual(result.get("region"), "FLORIDA")
        self.assertEqual(result.get("city"), "MIAMI")

        mock_get.assert_called_once_with("https://freeipapi.com/api/json/8.8.8.8")

    @patch("src.api_client.requests.get")
    def test_get_location_returns_side_effect(self, mock_get):
        mock_get.side_effect = [
            requests.exceptions.RequestException("Service Unavailable"),
            unittest.mock.Mock(
                status_code=200,
                json=lambda: {
                    "countryName": "USA",
                    "regionName": "FLORIDA",
                    "cityName": "MIAMI",
                },
            ),
            unittest.mock.Mock(
                status_code=400,
                json=lambda: {"error": "Invalid IP address"},
            ),
        ]

        # Primer intento: Falla por servicio no disponible
        with self.assertRaises(requests.exceptions.RequestException):
            get_location("8.8.8.8")

        # Segundo intento: Responde correctamente
        result = get_location("8.8.8.8")
        self.assertEqual(result.get("country"), "USA")
        self.assertEqual(result.get("region"), "FLORIDA")
        self.assertEqual(result.get("city"), "MIAMI")

        # Tercer intento: IP invÃ¡lida
        with self.assertRaises(ValueError) as context:
            get_location("999.999.999.999")

```

# Uso de Patching para Modificar Comportamientos en Python

Ahora vamos a aprender a modificar el comportamiento de objetos y funciones dentro de nuestras pruebas en Python, utilizando tÃ©cnicas como elÂ *patch*Â para simular situaciones especÃ­ficas, como el control del horario de retiro en una cuenta bancaria. Esta habilidad es crucial cuando necesitamos validar restricciones temporales o cualquier otra lÃ³gica de negocio que dependa de factores externos, como el tiempo.

## **Â¿CÃ³mo podemos restringir el horario de retiros en una cuenta bancaria?**

Para implementar la restricciÃ³n de horario, se utiliza la claseÂ `datetime`Â para obtener la hora actual. Definimos que los retiros solo pueden realizarse durante el horario de oficina: entre las 8 AM y las 5 PM. Cualquier intento fuera de este horario lanzarÃ¡ una excepciÃ³n personalizada llamadaÂ `WithdrawalError`.

- Se implementa la lÃ³gica en el mÃ©todo de retiro de la claseÂ `BankAccount`.
- La restricciÃ³n se basa en comparar la hora actual obtenida conÂ `datetime.now().hour`.
- Si la hora es menor que las 8 AM o mayor que las 5 PM, se lanza la excepciÃ³n.

```python
#src/exceptions.py
class InsufficientFundsError(Exception):
    pass

class WithdrawalTimeRestrictionError(Exception):
    pass
```

```python
#src/bank_account.py
class BankAccount:
    def __init__(self, balance=0, log_file=None):
        self.balance = balance
        self.log_file = log_file
        self._log_transaction("Cuenta creada")

    def _log_transaction(self, message):
        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(f"{message}\n")

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
            self._log_transaction(f"Deposited {amount}. New balance: {self.balance}")
        return self.balance

    def withdraw(self, amount):
        now = datetime.now()
        if now.hour < 8 or now.hour > 17:
            raise WithdrawalTimeRestrictionError("Withdrawals are only allowed from 8am to 5pm")

        if amount > self.balance:
            raise InsufficientFundsError(
                f"Withdrawal of {amount} exceeds balance {self.balance}"
            )
        if amount > 0:
            self.balance -= amount
            self._log_transaction(f"Withdrew {amount}. New balance: {self.balance}")
        return self.balance

    def get_balance(self):
        self._log_transaction(f"Checked balance. Current balance: {self.balance}")
        return self.balance
```

```python
#tests/test_bank_account.py
import unittest, os
from unittest.mock import patch
from src.exceptions import InsufficientFundsError, WithdrawalTimeRestrictionError
from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000, log_file="transaction_log.txt")

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)

    def _count_lines(self, filename):
        with open(filename, "r") as f:
            return len(f.readlines())

    def test_deposit_increases_balance_by_deposit_amount(self):
        new_balance = self.account.deposit(500)
        self.assertEqual(new_balance, 1500, "El balance no es igual")

    def test_withdraw_decreases_balance_by_withdraw_amount(self):
        new_balance = self.account.withdraw(200)
        self.assertEqual(new_balance, 800, "El balance no es igual")

    def test_get_balance_returns_current_balance(self):
        self.assertEqual(self.account.get_balance(), 1000)

    def test_deposit_logs_transaction(self):
        self.account.deposit(500)
        self.assertTrue(os.path.exists("transaction_log.txt"))

    def test_withdraw_logs_each_transaction(self):
        self.assertEqual(self._count_lines(self.account.log_file), 1)
        self.account.deposit(500)
        self.assertEqual(self._count_lines(self.account.log_file), 2)

    def test_withdraw_raises_error_when_insufficient_funds(self):
        with self.assertRaises(InsufficientFundsError):
            self.account.withdraw(2000)

    @patch("src.bank_account.datetime")
    def test_withdraw_during_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value.hour = 8
        new_balance = self.account.withdraw(100)
        self.assertEqual(new_balance, 900)

    @patch("src.bank_account.datetime")
    def test_withdraw_disallow_before_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value.hour = 7
        with self.assertRaises(WithdrawalTimeRestrictionError):
            self.account.withdraw(100)

    @patch("src.bank_account.datetime")
    def test_withdraw_disallow_after_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value.hour = 18
        with self.assertRaises(WithdrawalTimeRestrictionError):
            self.account.withdraw(100)
```

## **Â¿CÃ³mo podemos probar la funcionalidad de manera efectiva?**

Las pruebas unitarias permiten simular diferentes horas del dÃ­a para validar que las restricciones funcionen correctamente. Para lograrlo, usamos el decoradorÂ `patch`Â del mÃ³duloÂ `unittest.mock`, el cual modifica temporalmente el comportamiento de la funciÃ³nÂ `datetime.now()`.

- ConÂ `patch`, podemos definir un valor de retorno especÃ­fico paraÂ `now()`, como las 7 AM o las 10 AM.
- De esta forma, se puede validar que la excepciÃ³n se lance correctamente si el retiro ocurre fuera del horario permitido.
- En caso de que el retiro sea dentro del horario, la prueba verificarÃ¡ que el saldo de la cuenta se actualice correctamente.

## ğŸš€Â Reto.

Agrega una nueva funcionalidad a nuestra bank account, no permitas retiros ni sÃ¡bados ni domingos. Crea las pruebas unitarias para esos casos: haz una prueba para el domingo y otra para el lunes.

```python
#src/bank_account.py
from datetime import datetime
from src.exceptions import InsufficientFundsError, WithdrawalTimeRestrictionError

class BankAccount:
    def __init__(self, balance=0, log_file=None):
        self.balance = balance
        self.log_file = log_file
        self._log_transaction("Cuenta creada")

    def _log_transaction(self, message):
        if self.log_file:
            with open(self.log_file, "a") as f:
                f.write(f"{message}\n")

    def deposit(self, amount):
        if amount > 0:
            self.balance += amount
            self._log_transaction(f"Deposited {amount}. New balance: {self.balance}")
        return self.balance

    def withdraw(self, amount):
        now = datetime.now()

        # Bloquear retiros en sÃ¡bado (5) y domingo (6)
        if now.weekday() in [5, 6]:
            raise WithdrawalTimeRestrictionError("Withdrawals are not allowed on weekends")

        if now.hour < 8 or now.hour > 17:
            raise WithdrawalTimeRestrictionError("Withdrawals are only allowed from 8am to 5pm")

        if amount > self.balance:
            raise InsufficientFundsError(
                f"Withdrawal of {amount} exceeds balance {self.balance}"
            )
        if amount > 0:
            self.balance -= amount
            self._log_transaction(f"Withdrew {amount}. New balance: {self.balance}")
        return self.balance

    def get_balance(self):
        self._log_transaction(f"Checked balance. Current balance: {self.balance}")
        return self.balance

```

```python
#tests/test_bank_account.py
import unittest, os
from unittest.mock import patch
from datetime import datetime
from src.exceptions import InsufficientFundsError, WithdrawalTimeRestrictionError
from src.bank_account import BankAccount

class BankAccountTests(unittest.TestCase):

    def setUp(self) -> None:
        self.account = BankAccount(balance=1000, log_file="transaction_log.txt")

    def tearDown(self) -> None:
        if os.path.exists(self.account.log_file):
            os.remove(self.account.log_file)

    def _count_lines(self, filename):
        with open(filename, "r") as f:
            return len(f.readlines())

    def test_deposit_increases_balance_by_deposit_amount(self):
        new_balance = self.account.deposit(500)
        self.assertEqual(new_balance, 1500, "El balance no es igual")

    def test_withdraw_decreases_balance_by_withdraw_amount(self):
        new_balance = self.account.withdraw(200)
        self.assertEqual(new_balance, 800, "El balance no es igual")

    def test_get_balance_returns_current_balance(self):
        self.assertEqual(self.account.get_balance(), 1000)

    def test_deposit_logs_transaction(self):
        self.account.deposit(500)
        self.assertTrue(os.path.exists("transaction_log.txt"))

    def test_withdraw_logs_each_transaction(self):
        self.assertEqual(self._count_lines(self.account.log_file), 1)
        self.account.deposit(500)
        self.assertEqual(self._count_lines(self.account.log_file), 2)

    def test_withdraw_raises_error_when_insufficient_funds(self):
        with self.assertRaises(InsufficientFundsError):
            self.account.withdraw(2000)

    @patch("src.bank_account.datetime")
    def test_withdraw_during_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value = datetime(2024, 2, 12, 8)  # Lunes 8:00 AM
        new_balance = self.account.withdraw(100)
        self.assertEqual(new_balance, 900)

    @patch("src.bank_account.datetime")
    def test_withdraw_disallow_before_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value = datetime(2024, 2, 12, 7)  # Lunes 7:00 AM
        with self.assertRaises(WithdrawalTimeRestrictionError):
            self.account.withdraw(100)

    @patch("src.bank_account.datetime")
    def test_withdraw_disallow_after_bussines_hours(self, mock_datetime):
        mock_datetime.now.return_value = datetime(2024, 2, 12, 18)  # Lunes 6:00 PM
        with self.assertRaises(WithdrawalTimeRestrictionError):
            self.account.withdraw(100)

    @patch("src.bank_account.datetime")
    def test_withdraw_disallow_on_sunday(self, mock_datetime):
        mock_datetime.now.return_value = datetime(2024, 2, 11, 10)  # Domingo 10:00 AM
        with self.assertRaises(WithdrawalTimeRestrictionError):
            self.account.withdraw(100)

    @patch("src.bank_account.datetime")
    def test_withdraw_allow_on_monday(self, mock_datetime):
        mock_datetime.now.return_value = datetime(2024, 2, 12, 10)  # Lunes 10:00 AM
        new_balance = self.account.withdraw(100)
        self.assertEqual(new_balance, 900)

```

# ğŸ”¹Â ExploraciÃ³n de Herramientas y MÃ©todos Complementarios

# CÃ³mo parametrizar pruebas en Python con SubTest

El uso de SubTest en UnitTest te permite optimizar tus pruebas evitando la duplicaciÃ³n de cÃ³digo. Imagina que necesitas probar un mÃ©todo con varios valores diferentes. Sin SubTest, tendrÃ­as que crear varias pruebas casi idÃ©nticas, lo que resulta ineficiente. SubTest permite parametrizar pruebas, lo que significa que puedes ejecutar la misma prueba con diferentes valores sin repetir el cÃ³digo.

## **Â¿CÃ³mo evitar la duplicaciÃ³n de pruebas con SubTest?**

Al utilizar SubTest, puedes definir todos los valores que deseas probar en una lista o diccionario. Luego, iteras sobre estos valores mediante un bucleÂ `for`, ejecutando la misma prueba con cada conjunto de parÃ¡metros. AsÃ­, si es necesario modificar la prueba, solo tienes que hacer cambios en un Ãºnico lugar.

## **Â¿CÃ³mo implementar SubTest en un caso prÃ¡ctico?**

Para ilustrarlo, se puede crear una prueba llamadaÂ `test_deposit_various_values`. En lugar de duplicar la prueba con diferentes valores de depÃ³sito, utilizas un diccionario que contiene los valores a probar y el resultado esperado. DespuÃ©s, recorres estos valores con SubTest usando la estructuraÂ `with self.subTest(case=case)`Â y ejecutas la prueba para cada valor del diccionario. Esto asegura que cada prueba sea independiente y evita sumar valores a la cuenta de manera incorrecta.

## **Â¿CÃ³mo gestionar errores con SubTest?**

SubTest tambiÃ©n es Ãºtil para identificar errores especÃ­ficos. Si una prueba falla con un conjunto particular de parÃ¡metros, SubTest te permite ver fÃ¡cilmente quÃ© valores causaron el fallo. Esto facilita mucho la correcciÃ³n de errores, ya que puedes aislar rÃ¡pidamente los casos problemÃ¡ticos y corregirlos de manera eficiente.

```python
#tests/test_bank_account.py
#...

def test_deposit_multiple_amounts(self):
    test_cases = [
        {"ammount": 100, "expected": 1100},
        {"ammount": 3000, "expected": 4000},
        {"ammount": 4500, "expected": 5500},
    ]
    
    for case in test_cases:
        with self.subTest(case=case): 
            self.setUp()  # Reinicia el estado para cada caso
            new_balance = self.account.deposit(case["ammount"])
            self.assertEqual(new_balance, case["expected"])
```

# DocumentaciÃ³n de pruebas unitarias con Doctest en Python

El uso de Doctest es una herramienta poderosa que te permite escribir pruebas directamente en la documentaciÃ³n del cÃ³digo, lo que facilita que otros desarrolladores comprendan y verifiquen los resultados esperados. AdemÃ¡s de los Unit Tests tradicionales, Doctest permite que tus comentarios sean interactivos, ofreciendo ejemplos funcionales que se ejecutan dentro del cÃ³digo de Python. Veamos cÃ³mo puedes utilizarlo de manera eficiente.

## **Â¿QuÃ© es Doctest y cÃ³mo se usa?**

Doctest es una librerÃ­a que estÃ¡ incluida en Python y que permite crear pruebas en los comentarios del cÃ³digo. Esto lo hace prÃ¡ctico ya que puedes escribir pruebas de manera muy similar a una sesiÃ³n interactiva de Python. Solo debes aÃ±adir los ejemplos dentro de los comentarios y ejecutarlos con el comandoÂ `python -m doctest`.

## **Â¿CÃ³mo se estructuran las pruebas en Doctest?**

Para escribir una prueba, simplemente crea un comentario que simule una sesiÃ³n interactiva. Estas sesiones se caracterizan por comenzar conÂ `>>>`. Por ejemplo, si tienes una funciÃ³n de suma en tu claseÂ `Calculator`, podrÃ­as escribir lo siguiente:

```python
>>> sum(5, 7)
12

```

Esto se ejecutarÃ¡ como si estuvieras en el shell de Python, y esperarÃ¡ que la salida seaÂ `12`. Si el resultado no coincide con lo esperado, Doctest te notificarÃ¡ el error.

## **Â¿QuÃ© hacer si hay un error en la prueba?**

Si Doctest encuentra un error, revisa el mensaje de error y ajusta el cÃ³digo o la prueba segÃºn sea necesario. Por ejemplo, si ejecutas una prueba y esperabasÂ `12`Â pero el resultado fueÂ `11`, Doctest te informarÃ¡ de la discrepancia. Solucionas el error, corriges el comentario, y ejecutas nuevamente.

## **Â¿CÃ³mo manejar excepciones en Doctest?**

Doctest tambiÃ©n te permite probar excepciones. Si tienes una funciÃ³n que lanza unÂ `ValueError`Â al intentar dividir por cero, puedes capturar este comportamiento en el comentario:

```python
>>> divide(10, 0)
Traceback (most recent call last):
  ...
ValueError: DivisiÃ³n por 0 no permitida

```

Este tipo de pruebas asegura que las excepciones se manejen correctamente y ayuda a otros desarrolladores a entender los casos de error.

## **Â¿Por quÃ© es importante documentar con Doctest?**

La documentaciÃ³n clara es clave en cualquier proyecto de software, y Doctest facilita agregar ejemplos en el cÃ³digo que no solo explican cÃ³mo usar las funciones, sino que ademÃ¡s se prueban automÃ¡ticamente. Esto garantiza que la documentaciÃ³n estÃ© siempre alineada con el comportamiento real del cÃ³digo.

```python
#src/calculator
def sum(a, b):
    """
    >>> sum(5, 7)
    12

    >>> sum(4, -4)
    0
    """
    return a + b

def subtract(a, b):
    return a - b

def multiply(a, b):
    return a * b

def divide(a, b):
    """
    >>> divide(10, 0)
    Traceback (most recent call last):
    ValueError: La divisiÃ³n por cero no estÃ¡ permitida
    """

    if b == 0:
        raise ValueError("La divisiÃ³n por cero no estÃ¡ permitida")
    return a / b
```

## ğŸš€Â Reto.

El reto de este enfoque es agregar suficiente documentaciÃ³n con ejemplos ejecutables que cubran todos los casos, incluyendo los casos de borde, como divisiones por cero o parÃ¡metros invÃ¡lidos. Este proceso no solo mejora la calidad del cÃ³digo, sino tambiÃ©n la de la documentaciÃ³n, haciÃ©ndola mÃ¡s Ãºtil para todo el equipo.

# CÃ³mo generar datos de prueba dinÃ¡micos con Faker en Python

Generar datos de prueba puede ser una tarea tediosa, pero con la librerÃ­a Faker, este proceso se simplifica enormemente. Faker nos permite crear datos aleatorios como nombres, correos electrÃ³nicos y otros atributos de manera eficiente para validar la compatibilidad de nuestro cÃ³digo con diversas entradas. A continuaciÃ³n, exploramos cÃ³mo aprovechar Faker en pruebas automatizadas y cÃ³mo integrar la librerÃ­a en nuestro proyecto.

## **Â¿CÃ³mo instalar Faker y quÃ© ventajas ofrece?**

Para empezar a utilizar Faker, simplemente debemos instalarla a travÃ©s de la terminal con el comando:

```bash
pip install faker

```

Una vez instalada, podemos importarla en nuestro proyecto e instanciar un generador de datos aleatorios. Faker nos ofrece una gran variedad de mÃ©todos predefinidos para generar nombres, correos, cuentas bancarias, entre otros. La ventaja clave es que nos permite automatizar la generaciÃ³n de mÃºltiples entradas en cada ejecuciÃ³n de nuestras pruebas.

## **Â¿CÃ³mo integramos Faker en nuestro proyecto?**

Una vez que hemos instalado Faker, es esencial agregar la librerÃ­a a nuestro archivoÂ `requirements.txt`. Esto asegura que todas las dependencias se mantengan actualizadas y permite su instalaciÃ³n en futuros entornos. TambiÃ©n es importante definir una versiÃ³n fija para evitar problemas con actualizaciones inesperadas que puedan romper nuestro cÃ³digo.

## **Â¿CÃ³mo crear una clase User con Faker?**

Al integrar Faker, podemos crear pruebas mÃ¡s realistas. Por ejemplo, al generar datos para un usuario con mÃºltiples cuentas bancarias, podemos usar Faker para generar atributos como el nombre, correo electrÃ³nico y balances de cuentas de forma dinÃ¡mica. A continuaciÃ³n, se muestra un ejemplo de cÃ³mo podemos definir una claseÂ `User`Â y generar mÃºltiples cuentas con balances aleatorios:

- Se crea una claseÂ `User`Â que requiere un nombre, correo electrÃ³nico y una lista de cuentas bancarias.
- Faker se utiliza para generar estos valores automÃ¡ticamente en cada prueba.
- Se pueden generar mÃºltiples cuentas para un mismo usuario, iterando sobre un cicloÂ `for`Â para generar diferentes balances y archivos de log.

```python
#src/user.py
class User:
    def __init__(self, name, email):
        self.name = name
        self.email = email
        self.accounts = []
    
    def add_account(self, account):
        self.accounts.append(account)
    
    def get_total_balance(self):
        return sum(account.get_balance() for account in self.accounts)
```

```python
#tests/test_user.py
import unittest, os
from faker import Faker
from src.user import User
from src.bank_account import BankAccount

class UserTests(unittest.TestCase):
    def setUp(self) -> None:
        self.faker = Faker(locale="es")
        self.user = User(name=self.faker.name(), email=self.faker.email())
    
    def test_user_creation(self):
        name_generated = self.faker.name()
        email_generated = self.faker.email()
        user = User(name=name_generated, email=email_generated)
        self.assertEqual(user.name, name_generated)
        self.assertEqual(user.email, email_generated)
    
    def test_user_with_multiple_accounts(self):
        for _ in range(3):
            bank_account = BankAccount(
                balance=self.faker.random_int(min=100, max=2000, step=50),
                log_file=self.faker.file_name(extension=".txt")
            )
            self.user.add_account(account=bank_account)
        expected_value = self.user.get_total_balance()
        value = sum(account.get_balance() for account in self.user.accounts)
        self.assertEqual(value, expected_value)
    
    def tearDown(self) -> None:
        for account in self.user.accounts:
            os.remove(account.log_file)
```

## **Â¿CÃ³mo se estructuran las pruebas con Faker?**

En nuestras pruebas unitarias, podemos instanciar Faker en el mÃ©todoÂ `setUp`Â para reutilizarla en todas las pruebas. Esto nos permite generar nombres y correos electrÃ³nicos dinÃ¡micos en cada ejecuciÃ³n. A continuaciÃ³n, se presentan los pasos clave para estructurar las pruebas:

1. Instanciamos Faker en el mÃ©todoÂ `setUp`.
2. Definimos pruebas para la creaciÃ³n de usuarios con mÃºltiples cuentas.
3. Utilizamos Faker para generar atributos aleatorios como balances y nombres de archivo.
4. Validamos que los valores generados sean correctos utilizandoÂ `assertEqual`Â para verificar la integridad de los datos.

## **Â¿QuÃ© otras configuraciones y opciones ofrece Faker?**

Faker ofrece una amplia gama de configuraciones. Por ejemplo, podemos definir el idioma de los datos generados. Esto es Ãºtil si necesitamos que nuestros datos de prueba estÃ©n en espaÃ±ol o en otro idioma. TambiÃ©n es posible generar datos mÃ¡s complejos como nombres de archivos, paÃ­ses o incluso valores numÃ©ricos aleatorios con rangos definidos.

## **Â¿CÃ³mo limpiar el entorno de pruebas?**

Al generar archivos temporales durante las pruebas, es importante asegurarse de limpiar el entorno una vez que finalicen. Esto se puede hacer implementando un mÃ©todoÂ `tearDown`Â que borre los archivos generados durante la ejecuciÃ³n de las pruebas, garantizando que el entorno de pruebas se mantenga limpio.

# ğŸ”¹Â Mejora y AutomatizaciÃ³n de Pruebas

# Â¿CÃ³mo asegurar la cobertura de pruebas con Coverage en Python?

En los proyectos grandes de software, resulta difÃ­cil identificar quÃ© partes del cÃ³digo estÃ¡n correctamente probadas y cuÃ¡les no lo estÃ¡n. Por ello, es esencial usar herramientas como Coverage, que nos permite analizar quÃ© porciones de nuestro cÃ³digo han sido ejecutadas durante las pruebas y cuÃ¡les no. Esto facilita la detecciÃ³n de Ã¡reas que necesitan cobertura adicional.

## **Â¿QuÃ© es Coverage y cÃ³mo funciona?**

Coverage es una herramienta que se ejecuta junto a las pruebas y captura un reporte sobre quÃ© partes del cÃ³digo han sido probadas. Una vez finalizado el proceso, genera un informe detallado que indica quÃ© porcentaje del cÃ³digo estÃ¡ cubierto. De esta manera, puedes identificar quÃ© secciones de cÃ³digo necesitan nuevas pruebas.

## **Â¿CÃ³mo instalar y utilizar Coverage?**

Para instalar Coverage en un proyecto Python, sigue los siguientes pasos:

- Abre la terminal e instala la herramienta conÂ `pip install coverage`.
- DespuÃ©s, usaÂ `pip freeze | grep coverage`Â para agregar la librerÃ­a a tu archivo de requirements.
- Una vez instalada, ejecuta el comandoÂ `coverage run -m unittest discover -s tests`, que corre las pruebas en la carpetaÂ `tests`.

## **Â¿CÃ³mo generar el reporte de cobertura?**

Para generar el informe de cobertura de cÃ³digo:

1. Usa el comandoÂ `coverage report`Â para obtener un resumen de las pruebas.
2. Si quieres un reporte visual mÃ¡s detallado, ejecutaÂ `coverage html`. Esto crearÃ¡ una carpeta con archivos HTML que podrÃ¡s abrir en el navegador.

## **Â¿CÃ³mo mejorar el reporte excluyendo archivos de prueba?**

Para evitar que los archivos de prueba aparezcan en el reporte, agrega el parÃ¡metroÂ `--source=src`Â al comandoÂ `coverage run`. Esto asegura que solo se evalÃºe el cÃ³digo fuente de la aplicaciÃ³n y no las pruebas en sÃ­ mismas.

## **Â¿CÃ³mo detectar y corregir cÃ³digo sin pruebas?**

Coverage permite identificar lÃ­neas especÃ­ficas que no han sido probadas. Usando el reporte HTML, puedes hacer clic en los archivos para ver las lÃ­neas de cÃ³digo no ejecutadas. Un ejemplo serÃ­a la detecciÃ³n de un mÃ©todo que no maneja una divisiÃ³n por cero. Al agregar un test para esta excepciÃ³n, puedes aumentar la cobertura total del proyecto.

## **Â¿CÃ³mo validar un porcentaje mÃ­nimo de cobertura?**

En proyectos con equipos grandes, es recomendable establecer un porcentaje mÃ­nimo de cobertura, como un 80%, para garantizar la calidad del cÃ³digo. Esto se puede configurar en la documentaciÃ³n de Coverage.

# AutomatizaciÃ³n de Pruebas Unitarias en Python con GitHub Actions

Integrar una suite de pruebas en un sistema de Continuous Integration (CI) es clave para automatizar el proceso de verificaciÃ³n de cambios en el cÃ³digo. En este caso, usaremos GitHub Actions para correr nuestras pruebas de manera automÃ¡tica cada vez que haya un cambio en el repositorio, asegurÃ¡ndonos de que el cÃ³digo estÃ© siempre funcionando correctamente.

## **Â¿CÃ³mo configurar tu primera GitHub Action?**

Primero, accede a la pestaÃ±a de â€œActionsâ€ dentro de tu repositorio en GitHub. AhÃ­ encontrarÃ¡s un Marketplace con varias opciones. Busca â€œPythonâ€ y selecciona la Action â€œPython Applicationâ€. Esta configuraciÃ³n correrÃ¡ pruebas automÃ¡ticamente cada vez que haya un push o un pull request hacia la rama â€œMainâ€.

## **Â¿QuÃ© pasos incluye el workflow de pruebas?**

- **ClonaciÃ³n del repositorio:**Â El workflow comienza clonando tu cÃ³digo, similar a unÂ `git clone`.
- **ConfiguraciÃ³n de Python:**Â Utiliza la versiÃ³n 3.10 de Python, asegurando compatibilidad con el cÃ³digo del proyecto.
- **InstalaciÃ³n de dependencias:**Â Ejecuta las instalaciones de las librerÃ­as listadas en el archivoÂ `requirements.txt`, por ejemplo, Faker y Coverage.
- **ModificaciÃ³n del comando de pruebas:**Â En lugar de utilizar un test genÃ©rico, el comando se cambia aÂ `python -m unittest discover test`, adaptado a las pruebas unitarias del proyecto.

## **Â¿CÃ³mo verificar si el workflow fue exitoso?**

Una vez configurado el archivo y hecho el commit, puedes ver el progreso de la ejecuciÃ³n en la pestaÃ±a de â€œActionsâ€. Si todo saliÃ³ bien, aparecerÃ¡ un checkmark verde indicando que las pruebas pasaron exitosamente.

## **Â¿CÃ³mo mejorar la cobertura de pruebas en tu pipeline?**

El reto adicional consiste en ejecutar las pruebas con diferentes versiones de Python utilizando Matrix en GitHub Actions. Esto te permitirÃ¡ probar tu cÃ³digo en varios entornos, asegurando mayor robustez y evitando problemas de compatibilidad.

# Pruebas Unitarias con PyTest en Python

Python ofrece una gran variedad de herramientas, y una de las mÃ¡s Ãºtiles para pruebas automatizadas es PyTest. PyTest mejora considerablemente la experiencia del desarrollador al permitir escribir y ejecutar pruebas de manera mÃ¡s eficiente. En esta guÃ­a veremos cÃ³mo instalar PyTest, crear pruebas parametrizadas y ejecutar un ejemplo bÃ¡sico.

## **Â¿CÃ³mo instalar y configurar PyTest?**

- Abre la terminal y ejecuta el siguiente comando para instalar PyTest:
    
    ```
    pip install pytest
    
    ```
    
- Recuerda agregarlo a tu archivoÂ `requirements.txt`Â con:
    
    ```
    pip freeze | grep pytest > requirements.txt
    
    ```
    

## **Â¿CÃ³mo crear una prueba con PyTest?**

1. En la carpeta de pruebas, crea un archivo llamadoÂ `test_pytest.py`.
2. Importa PyTest en tu archivo:
    
    ```python
    import pytest
    
    ```
    
3. Crea una funciÃ³n de prueba simple como esta:
    
    ```python
    def test_suma():
        a = 4
        b = 4
        assert a + b == 8
    
    ```
    
4. Ejecuta la prueba con el siguiente comando:
    
    ```
    pytest test_pytest.py
    
    ```
    

PyTest no requiere la creaciÃ³n de clases para agrupar pruebas, lo cual simplifica el cÃ³digo. En este caso, las pruebas se agrupan por archivo.

## **Â¿CÃ³mo parametrizar una prueba en PyTest?**

1. Utiliza decoradores de PyTest para parametrizar la prueba:
    
    ```python
    @pytest.mark.parametrize("amount, expected", [
        (100, 5000),
        (200, 5500),
        (300, 6000)
    ])
    def test_balance(amount, expected):
        assert calcular_balance(amount) == expected
    
    ```
    
2. En este ejemplo, la funciÃ³n de prueba recibe varios casos con valores diferentes deÂ `amount`Â yÂ `expected`.
3. Ejecuta las pruebas:
    
    ```
    pytest -v
    
    ```
    

## **Â¿QuÃ© ventajas ofrece PyTest al ejecutar pruebas?**

- PyTest ofrece mensajes de error detallados y fÃ¡ciles de leer, resaltados con colores.
- Los errores incluyen los valores especÃ­ficos que causaron la falla.
- Con la opciÃ³nÂ `v`, PyTest detalla quÃ© pruebas se ejecutaron y sus resultados.

## **Â¿QuÃ© ocurre si una prueba falla?**

Si una prueba falla, PyTest te indicarÃ¡ exactamente quÃ© valores no coincidieron. Por ejemplo, si uno de los valores esperados es incorrecto:

```python
def test_balance():
    assert calcular_balance(100) == 5400  # Este valor estÃ¡ incorrecto

```

Al ejecutar nuevamente la prueba, PyTest te mostrarÃ¡ la diferencia entre el valor esperado y el real.

## ğŸš€Â Reto

Refactoriza todas las pruebas de tu proyecto para que utilicen PyTest, aplicando lo que hemos visto sobre parametrizaciÃ³n y el uso de asserts mÃ¡s sencillos.

# CÃ³mo crear pruebas unitarias con inteligencia artificial en Python

Las herramientas de inteligencia artificial han revolucionado la forma en que desarrollamos software, simplificando tareas como la creaciÃ³n de pruebas unitarias. Estas herramientas permiten generar pruebas mÃ¡s rÃ¡pido y con mayor precisiÃ³n, ahorrando tiempo y reduciendo errores. A continuaciÃ³n, exploramos algunas herramientas clave que todo desarrollador deberÃ­a conocer.

## **Â¿QuÃ© es GitHub Copilot y cÃ³mo puede ayudarte a escribir pruebas?**

GitHub Copilot es una extensiÃ³n que puedes instalar en tu editor de cÃ³digo. Con ella, puedes chatear, darle contexto sobre tu cÃ³digo y pedirle que genere pruebas unitarias. Esta herramienta se integra directamente en el flujo de trabajo del desarrollador, lo que facilita la creaciÃ³n de pruebas con pocos comandos. Al escribir un prompt claro, como â€œcreate a test that doesnâ€™t allow the deposit to be negativeâ€, Copilot genera automÃ¡ticamente el cÃ³digo de la prueba, optimizando el proceso de TDD (desarrollo guiado por pruebas).

### Beneficios de usar GitHub Copilot:

- Ahorra tiempo generando pruebas automÃ¡ticamente.
- Mejora la precisiÃ³n al sugerir cÃ³digo basado en grandes bases de datos de proyectos.
- Facilita la integraciÃ³n en editores populares como Visual Studio Code.

## **Â¿QuÃ© ofrece Supermaven y cÃ³mo se compara con otras herramientas?**

Supermaven es una herramienta similar que permite integrar la API de ChatGPT directamente en tu editor de cÃ³digo. Con esta integraciÃ³n, puedes utilizar las capacidades de ChatGPT para generar y modificar pruebas en tiempo real. Lo interesante de Supermaven es que utiliza la misma suscripciÃ³n de ChatGPT, lo que lo convierte en una opciÃ³n versÃ¡til y eficiente para desarrolladores que ya usan esta IA.

### CaracterÃ­sticas destacadas de Supermaven:

- Compatibilidad con mÃºltiples editores de cÃ³digo.
- Capacidad para modificar pruebas segÃºn el contexto que le proporciones.
- Soporte para autocompletar cÃ³digo y optimizar la generaciÃ³n de pruebas unitarias.

## **Â¿CÃ³mo usar ChatGPT para generar y modificar pruebas?**

ChatGPT es otra herramienta clave para generar pruebas. Al darle contexto sobre el cÃ³digo, como la claseÂ `BankAccount`, puedes solicitar que modifique o cree pruebas unitarias parametrizadas, lo que simplifica aÃºn mÃ¡s el proceso de validaciÃ³n. Esta interacciÃ³n con la IA facilita la generaciÃ³n de pruebas mÃ¡s completas, incluyendo distintos casos de prueba como depÃ³sitos positivos y negativos.

### Proceso de uso de ChatGPT para pruebas:

1. Proporciona el contexto del cÃ³digo.
2. Pide que modifique o cree una prueba especÃ­fica.
3. Analiza y ejecuta el cÃ³digo generado para verificar su funcionalidad.

## **Â¿CuÃ¡les son las precauciones al usar herramientas de inteligencia artificial para pruebas?**

Es crucial recordar que, aunque estas herramientas son extremadamente Ãºtiles, no debes copiar y pegar cÃ³digo sin antes revisarlo. La IA utiliza grandes bases de datos de cÃ³digo, algunos de los cuales pueden contener errores o prÃ¡cticas no recomendadas. Es importante que valides siempre el cÃ³digo generado antes de implementarlo en producciÃ³n.

### Consejos para un uso adecuado:

- Revisa cuidadosamente cada sugerencia antes de integrarla a tu cÃ³digo.
- AsegÃºrate de que las pruebas cubran todos los casos posibles.
- Ajusta el cÃ³digo generado segÃºn las mejores prÃ¡cticas de tu equipo o proyecto.

## **Â¿QuÃ© otras buenas prÃ¡cticas debes seguir al escribir pruebas unitarias?**

AdemÃ¡s de usar herramientas de IA, existen otras buenas prÃ¡cticas que debes tener en cuenta al desarrollar pruebas unitarias:

- Agrupa las pruebas por funcionalidad o clase.
- Utiliza herramientas comoÂ `coverage`Â para verificar quÃ© partes del cÃ³digo no han sido probadas.
- Borra los comentarios generados automÃ¡ticamente para mantener el cÃ³digo limpio.

## **5. Recursos Adicionales**

### **DocumentaciÃ³n Oficial**

- [unittest â€” Marco de pruebas unitarias en Python](https://docs.python.org/3/library/unittest.html)
- [assert Methods en unittest](https://docs.python.org/3/library/unittest.html#assert-methods)

### **ArtÃ­culos Relacionados**

- ["Getting Started with unittest in Python"](https://realpython.com/python-testing/)
- ["Python Unit Testing with unittest"](https://www.guru99.com/unit-test-python.html)
- ["How to Write Unit Tests in Python"](https://dev.to/mohammadfaisal/testing-in-python-with-unittest-3e0f)

### **Videos Recomendados**

- [Python unittest Tutorial for Beginners (YouTube)](https://www.youtube.com/watch?v=6tNS--WetLI)